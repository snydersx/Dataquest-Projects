{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion MNIST:https://becominghuman.ai/step-by-step-neural-network-tutorial-for-beginner-cc71a04eedeb\n",
    "CNN: https://thedatamage.com/convolutional-neural-network-explained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation-Test split\n",
    "\n",
    "This step is the train-validation-test split. This splits your data into three portions.\n",
    "\n",
    "The training data is self-explanatory. Generally, a larger amount of training data quantity will make your Neural Network better understand your data distribution. More data will make your trained network do better. Always put the priority on this portion of the split.\n",
    "\n",
    "Next is the validation data. It is the portion of data which will be evaluated against during the training process. This data is used to estimate the prediction error.\n",
    "\n",
    "Finally, the test data. This is the data used to evaluate the neural network model. If the network performs well on the test data, you can bring the network to the production level.\n",
    "\n",
    "If your data is not that many, maybe in thousands or tens of thousands, then use 70–10–20 as the split strategy. 70% of the data are split into training, 10% into validation, and 20% into the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every neural network project you will do in the future, these rules always apply.\n",
    "\n",
    "1. Start simple. Use a single layer perceptron and evaluate the result. If it is good, then proceed to deployment.\n",
    "\n",
    "2. If the previous step is not good enough, try to get your network wider and/or deeper. Add several neurons in your single-layer perceptron. Or, add one layer into the existing network. Evaluate and, if it is good, proceed to deployment. If not, then iterate by adding more neurons or layers.\n",
    "\n",
    "3. When, after adding several more layers into your network, but the results are still not good, then maybe you need to change your network architecture. Use Convolutional Neural Network (CNN) for images or Recurring Neural Network for time-series and texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network building code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Single-layer perceptron\n",
    "Let’s start our neural network with a perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/1920/1*K0D3JOZJUTxX4Q-9CpiALw.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://miro.medium.com/max/1920/1*K0D3JOZJUTxX4Q-9CpiALw.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our image is 28x28, and therefore is two-dimensional. Because of our perceptron only able to read one-dimensional data, let’s flatten them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that the size changed into 784 because of the flatten. Print y_train.shape and y_test.shape to see your data size.\n",
    "\n",
    "Your training data x_train is transformed from 60,000 x 28 x 28 to 60,000 x 784. Your testing data x_test follows suit, from 10,000 x 28 x 28 to 10,000 x 784.\n",
    "\n",
    "For the hidden layer, let’s set an arbitrary number of neurons. The number should be simple and small enough to follow our step number 1. Let’s choose 10 neurons.\n",
    "\n",
    "While for the output layer, because we have ten categories to categorize, we need to set it to 10 output neurons. For each image, each of these neurons will be filled with 1 if it is the correct category and 0 if not.\n",
    "\n",
    "In an example, if you have a Sandal image, then the output layer should have something like this [0 0 0 0 0 1 0 0 0 0]. The index for Sandal category (5) should be 1, the other should be 0. Remember, the array is zero-indexed. The sixth item should be index number 5.\n",
    "\n",
    "The output layer is called One-Hot Vector, when it is hot then the value is 1, the others should be all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=784, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sequential model is the easiest model Keras has. The first line of model.add method is adding your hidden layer with 10 cells, coming from 784 input cells.\n",
    "\n",
    "The second add method is adding your output layer to the network. This has 10 cells as I elaborated before.\n",
    "\n",
    "The Relu and Softmax activation options are non-linear. Being able to use non-linear data makes Neural Network particularly useful. Generally, neural networks can map any data distribution at any level of complexity.\n",
    "You don’t have to know what Relu and Softmax are. These are too complex for a beginner. You just need to follow these tips:\n",
    "\n",
    "1. Use Relu whenever possible, on every hidden layer.\n",
    "2. Use Softmax on output layers with more than two categories to be predicted.\n",
    "3. Use Sigmoid on an output layer with two categories.\n",
    "\n",
    "After creating your model, call compile method to finish your model. It usually takes three parameters. Always use categorical_crossentropy for multi-categories, and binary_crossentropy for two categories. Use adam or rmsprop as the optimizer since both of them are pretty good. And you need accuracy as the metric to check your network performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 3s 60us/sample - loss: 0.6819 - acc: 0.7671 - val_loss: 0.4936 - val_acc: 0.8240\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 3s 53us/sample - loss: 0.4722 - acc: 0.8372 - val_loss: 0.4474 - val_acc: 0.8428\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 3s 53us/sample - loss: 0.4448 - acc: 0.8466 - val_loss: 0.4366 - val_acc: 0.8448\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 3s 53us/sample - loss: 0.4294 - acc: 0.8508 - val_loss: 0.4265 - val_acc: 0.8502\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 3s 56us/sample - loss: 0.4179 - acc: 0.8559 - val_loss: 0.4298 - val_acc: 0.8438\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 3s 56us/sample - loss: 0.4091 - acc: 0.8586 - val_loss: 0.4120 - val_acc: 0.8522\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 3s 55us/sample - loss: 0.4025 - acc: 0.8606 - val_loss: 0.4316 - val_acc: 0.8440\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 3s 55us/sample - loss: 0.3973 - acc: 0.8614 - val_loss: 0.4245 - val_acc: 0.8527\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 3s 54us/sample - loss: 0.3933 - acc: 0.8621 - val_loss: 0.4130 - val_acc: 0.8540\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 3s 55us/sample - loss: 0.3898 - acc: 0.8640 - val_loss: 0.4057 - val_acc: 0.8582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x64c62c150>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 10% of the training data as the validation data, hence validation_split was set to 0.1.\n",
    "\n",
    "epochs is the number of training loops we will do. \n",
    "\n",
    "One epoch will expose all of our training data once to the network. More epochs means the network will know better about our data.\n",
    "\n",
    "You get 85% accuracy on validation data.\n",
    "You don't see the training data accuracy, because it should have 100% accuracy. What matters is the accuracy of the validation data. Since it has not seen any of the validation data, we can see how well it can generalize.\n",
    "Let’s see on to the testing data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.4346 - acc: 0.8468\n",
      "0.8468\n"
     ]
    }
   ],
   "source": [
    "_, test_acc = model.evaluate(x_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you will get around 84% accuracy on test data. Good enough for this simple architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make network wider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 4s 81us/sample - loss: 0.5414 - acc: 0.8142 - val_loss: 0.4304 - val_acc: 0.8442\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 4s 75us/sample - loss: 0.4056 - acc: 0.8560 - val_loss: 0.3744 - val_acc: 0.8665\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 4s 77us/sample - loss: 0.3688 - acc: 0.8681 - val_loss: 0.3567 - val_acc: 0.8727\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 4s 69us/sample - loss: 0.3438 - acc: 0.8755 - val_loss: 0.3572 - val_acc: 0.8688\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 4s 68us/sample - loss: 0.3257 - acc: 0.8824 - val_loss: 0.3515 - val_acc: 0.8738\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 4s 70us/sample - loss: 0.3113 - acc: 0.8854 - val_loss: 0.3554 - val_acc: 0.8693\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 4s 70us/sample - loss: 0.3003 - acc: 0.8902 - val_loss: 0.3284 - val_acc: 0.8815\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 4s 67us/sample - loss: 0.2903 - acc: 0.8931 - val_loss: 0.3463 - val_acc: 0.8778\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 4s 67us/sample - loss: 0.2778 - acc: 0.8978 - val_loss: 0.3231 - val_acc: 0.8852\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 4s 67us/sample - loss: 0.2706 - acc: 0.9009 - val_loss: 0.3393 - val_acc: 0.8798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x653133190>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Dense(50,input_dim=784,activation='relu'))\n",
    "model2.add(Dense(10,activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model2.fit(x_train,y_train,epochs=10,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 0.9009, pretty good. A bigger network can imprive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 39us/sample - loss: 0.3586 - acc: 0.8770\n",
      "0.877\n"
     ]
    }
   ],
   "source": [
    "_,test_acc=model2.evaluate(x_test,y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better improvment. Let's go deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a deeper network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 6s 103us/sample - loss: 0.5388 - acc: 0.8101 - val_loss: 0.4268 - val_acc: 0.8460\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 5s 93us/sample - loss: 0.4013 - acc: 0.8573 - val_loss: 0.3891 - val_acc: 0.8612\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 5s 90us/sample - loss: 0.3628 - acc: 0.8678 - val_loss: 0.3765 - val_acc: 0.8627\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 5s 89us/sample - loss: 0.3386 - acc: 0.8770 - val_loss: 0.3497 - val_acc: 0.8752\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 5s 91us/sample - loss: 0.3220 - acc: 0.8822 - val_loss: 0.3550 - val_acc: 0.8705\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 5s 90us/sample - loss: 0.3059 - acc: 0.8878 - val_loss: 0.3586 - val_acc: 0.8732\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 5s 87us/sample - loss: 0.2948 - acc: 0.8904 - val_loss: 0.3352 - val_acc: 0.8820\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 5s 88us/sample - loss: 0.2871 - acc: 0.8937 - val_loss: 0.3419 - val_acc: 0.8808\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 5s 88us/sample - loss: 0.2740 - acc: 0.8983 - val_loss: 0.3253 - val_acc: 0.8828\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 5s 87us/sample - loss: 0.2659 - acc: 0.9009 - val_loss: 0.3330 - val_acc: 0.8792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x652d869d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3=Sequential()\n",
    "model3.add(Dense(50,input_dim=784,activation='relu'))\n",
    "model3.add(Dense(50,activation='relu'))\n",
    "model3.add(Dense(10,activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model3.fit(x_train,y_train,epochs=10,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added another hidden layer with 50 cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 0.9 which is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 50us/sample - loss: 0.3459 - acc: 0.87710s - loss: 0.3580 - acc: 0.\n"
     ]
    }
   ],
   "source": [
    "_,test_acc=model3.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 0,88 which is not that big. Maybe the approach was not the right by using peceptron, let's try another method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/790/1*eAJeVQry42C4DmArr95NUQ.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://miro.medium.com/max/790/1*eAJeVQry42C4DmArr95NUQ.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convolutional neural network (CNN) is a neural network that can “see ” a subset of our data. It can detect a pattern in images better than perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train[:,:,:,np.newaxis] / 255.0\n",
    "x_test = x_test[:,:,:,np.newaxis] / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s import the necessary methods and reshape our training data. You can’t flatten it because CNN reads our images as is.\n",
    "\n",
    "If you check your x_train, you will have 60,000 x 28 x 28 x 1 data.\n",
    "\n",
    "Why x 1?\n",
    "\n",
    "The data CNN needs to read must be like this: total_data x width x height x channels.\n",
    "Height and width are self-explanatory. Channels are like Red or Green or Blue in RGB images. In RGB, because there are three channels, we need to make the data x 3. But because we work with grayscale images, every value on Red, Green, or Blue channel is the same and we reduce to one channel.\n",
    "\n",
    "Let’s build the architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28, 1))) \n",
    "model4.add(MaxPooling2D(pool_size=2))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(10, activation='softmax'))\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is a little bit different. There are Conv2D, MaxPooling2D, and Flatten.\n",
    "These guys are the three most common layers to use in CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                125450    \n",
      "=================================================================\n",
      "Total params: 125,770\n",
      "Trainable params: 125,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv2d changes your 28x28x1 image to 28x28x64. Just imagine this as 64 hidden layer cells.\n",
    "\n",
    "MaxPooling2D reduces the width and height so that you will not need to compute all the cells. It reduces the size to 14x14x64.\n",
    "\n",
    "Finally, flatten just flattens out the output of MaxPooling into a hidden layer of 12544 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 22s 403us/sample - loss: 0.4425 - acc: 0.8469 - val_loss: 0.3432 - val_acc: 0.8777\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 21s 394us/sample - loss: 0.3166 - acc: 0.8882 - val_loss: 0.3030 - val_acc: 0.8925\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 22s 412us/sample - loss: 0.2835 - acc: 0.9003 - val_loss: 0.2926 - val_acc: 0.8955\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 21s 380us/sample - loss: 0.2605 - acc: 0.9079 - val_loss: 0.2806 - val_acc: 0.8993\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 20s 363us/sample - loss: 0.2438 - acc: 0.9126 - val_loss: 0.2952 - val_acc: 0.8975\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 19s 356us/sample - loss: 0.2307 - acc: 0.9167 - val_loss: 0.2783 - val_acc: 0.9018\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 22s 412us/sample - loss: 0.2186 - acc: 0.9227 - val_loss: 0.2905 - val_acc: 0.8998\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 20s 369us/sample - loss: 0.2073 - acc: 0.9266 - val_loss: 0.2844 - val_acc: 0.9025\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 19s 358us/sample - loss: 0.1969 - acc: 0.9302 - val_loss: 0.2691 - val_acc: 0.9065\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 19s 352us/sample - loss: 0.1898 - acc: 0.9323 - val_loss: 0.2671 - val_acc: 0.9068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x652dd2850>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 118us/sample - loss: 0.2814 - acc: 0.9022\n"
     ]
    }
   ],
   "source": [
    "_,test_acc=model4.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is more than 90%. A single layer of CNN can do better than perceptron same with test "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
